\documentclass[12pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

\usepackage[legalpaper, margin=1in]{geometry}

\title{A Review on \\
  Deep Learning for Universal Linear Embeddings of Nonlinear Dynamics \cite{lusch2018deep}}
\author{Alvin Sun}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
  System identification remains one of the most important areas in control and
  signal processing. The importance comes from the fact that many system in practice
  has unknown governing equations, which makes applying classical control algorithms
  much harder. This work presented a way of estimating the underlying dynamics
  of arbitrary non-linear systems purely from measurement data. The authors utilized an
  autoencoder neural network to learn an parsimonious and interpretable dynamical
  represenation inside the approximated Koopman Operator space, where the dynamics
  are globally linearized by Koopman Theory. The network archiecture jointly
  learns the intrinsic coordinate transformation and a linear transition matrix.
  This work opened up possibilities in applying linear control and estimation
  theories to nonlinear systems.
\end{abstract}

\section{Introduction}

Many classical and modern control theories are built around systems with known dynamics.
Example from as simple as controlling an inverted pendulum to as complicated
as manipulating space crafts all require knowledge of the underlying governing equations
of those sytems. However, in practice, due to limitations such as fabrication precision,
physical phenomenon like thermal expansion, system can have unknown or even changing
dynamics. Accurately estimating those dynamics become a crucial part in control problems.
Recent years of rapid development in digital computing and sensing devices has made high
quality measurement data more readily available, which opened up many possibilities for
discovering dynamics equations from data. While control and estimation theories around
linear systems are relatively well developed, estimating for non-linear systems remains
a difficult problem especially when we have absolutely no a priori knowledge about the equations.
This also motivated researchers to come up with some methodology that can generically
recover arbitrary governing equations while relating to linear control and estimation theories.

\section{Background}

\subsection{Nonlinear System Identification}

The main objective is to determin an unknown function $f$ in a dynamic system
\begin{gather}
  \dot{x}= f(x)
\end{gather}
For the discrete case, the dynamics can be represented as
\begin{gather}\label{eqa:discrete}
  x_{k+1} = F(x_k)
\end{gather}
There are quite a few popular algorithms developed around
this data driven system ID problem.
Two of the popular ones are Dynamic Mode Decomposition (DMD) \cite{schmid2010dynamic} and
its varient eDMD \cite{williams2015data}, both of which use singular value decompositions to
approximate the dominating modes of a system. Both of the methods are also built
around Koopman Theory, which states that any nonlinear dynamics can be transformed
into linear dynamics inside an inifinite dimension Hilber space of possible nonlinear
measurements $y = g(x)$. Then the state transition can be expressed as a Koopman Operator,
$\mathcal{K}$, which is an inifinite dimensional linear operator.
\begin{gather}
  y_{k+1} = \mathcal{K}y_k \implies g(x_{k+1}) = \mathcal{K}g(x_k)
\end{gather}
Many methods, including this paper, are developed around
approximating this $\mathcal{K}$ operator with finite dimensional matrices.

\subsection{Neural Network and Autoencoder}

Autoencoder architectures are well known for its capability in compression
and latent space extraction. The training procedure automatically ensures
compressibility and reconstructability of the instrinsics measurement coordinates.
Using large number of neurons also enables neural networks to learn arbitrary nonlinear
transformations. Therefore, it is possible to learn a finite number of nonlinear
transformations that well approximate the dominant modes in $\mathcal{K}$.

\section{Methodologies}

This paper focuses on solving for discrete systems as shown in Equation~\ref{eqa:discrete}.
An autoencoder neural network is used to transform measurement input $x_k$
from potentially high dimensional space to a low dimensional ``latent space'' of
nonlinear measurements $z_k$. The coordinate transformation can then be expressed as
\begin{gather}
  z_k = \varphi(x_k) \\
  x_k \approx \phi(z_k)
\end{gather}
where $\varphi$ and $\phi$ are the encoder and decoder respectively.
The reconstruction is ensured by imposing $\|x_k - \phi(\varphi(x_k))\|_2$ as a loss function.
A linear state transition matrix $K$ that satisfies
\begin{gather}
  z_{k+1} = K z_k
\end{gather}
is also learned by penalizing on m-step future
predictions in both the transformed coordinates and the original coordinates. Namely, the
related loss terms are $\|z_{k+m} - K^m z_{k}\|$ and $\|x_{k+m} - \phi(K^m z_{k})\|$.
This paper also proposed an auxiliary network to identify a continuously varying
eigenvalue spectrum, which imposes constraints on the state transition matrix.
With this auxiliary block, the network is able to characterize continuous eigenvalue spectrums
such as sptially varying frequencies.

\section{Results and Impact}

This deep learned approximation of Koopman Operator successfully identified the following systems
\begin{enumerate}
  \item A simple system with discrete spectrum
  \item A nonlinear pendulum with continuous spectrum
  \item A high-dimensional nonlinear fluid flow model
\end{enumerate}
The major impact of this algorithm is the ability to automatically extract
relatively low-dimensional latent coordinate space that globally linearizes a system.
The auxiliary module also helps produce parsimonious models with interpretable
frequency modes.

\section{Discussion}

This paper, along with the previous work in DMD, opened up many possibilities of applying
linear theories to nonlinear dynamical systems. This method can be extended to incorporate
external control inputs into the system, so that linear control theories with nice
closed-form solutions may apply directly in that learned latent coordinate space.

\newpage

\bibliography{citations}
\bibliographystyle{ieeetr}

\end{document}
